{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e316f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dae2f8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_data = iris.data\n",
    "iris_target = iris.target\n",
    "\n",
    "\n",
    "iris_new_target = np.array([-1])\n",
    "iris_new_data = [iris_data[0]]\n",
    "\n",
    "for i in range(len(iris_target)-1):\n",
    "    if iris_target[i] == 1:\n",
    "        iris_new_target = np.append(iris_new_target,-1)\n",
    "        iris_new_data = np.append(iris_new_data, [iris_data[i+1]],axis = 0)\n",
    "    elif iris_target[i] == 2:\n",
    "        iris_new_target = np.append(iris_new_target,1)\n",
    "        iris_new_data = np.append(iris_new_data, [iris_data[i+1]],axis = 0)\n",
    "print(iris_new_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a7ce2bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [-1.98810285 -7.09847882  5.02217542  5.03022845]\n",
      "Wnest =  [-1.98806719 -7.0983133   5.02200061  5.03032088]\n",
      "Score = 0.8666666666666667\n",
      "Score_nest = 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "class logistic_regression:\n",
    "    \n",
    "    # производная в точке\n",
    "    def derivative_log_function(self,X,Y,W,j):\n",
    "        summ = 0\n",
    "        for i in range(len(Y)):\n",
    "            scal_prozv = np.dot(W,X[i])\n",
    "            summ += -Y[i]*X[i,j]*np.exp(-Y[i]*scal_prozv)/(1+np.exp(-Y[i]*scal_prozv))\n",
    "        return summ\n",
    "    \n",
    "    # метод градиентного спуска \n",
    "    def gradient_descent(self,X,Y,alpha,number_iter):\n",
    "        W=np.zeros(len(X[0]))\n",
    "    \n",
    "        for k in range(number_iter):\n",
    "            for j in range(len(X[0])):\n",
    "                W[j]=  W[j] - alpha*self.derivative_log_function(X,Y,W,j)\n",
    "        self.W = W\n",
    "        return W\n",
    "    \n",
    "    # метод нестерова\n",
    "    def nesterov_gradient_descent(self,X,Y,alpha,number_iter):\n",
    "        W_nest=np.zeros(len(X[0]))\n",
    "        v_x = 0\n",
    "        r_x = 0.1\n",
    "        for k in range(number_iter):\n",
    "            for j in range(len(X[0])):\n",
    "                old_v = v_x\n",
    "                v_x = r_x * v_x - alpha * self.derivative_log_function(X,Y,W_nest,j)\n",
    "                W_nest[j] = W_nest[j] - r_x * old_v + (1 + r_x) * v_x\n",
    "                \n",
    "        self.W_nest = W_nest\n",
    "        return W_nest\n",
    "    \n",
    "    # тест\n",
    "    def test(self,X_test,Y_test, W):\n",
    "        Y_calculation = np.array([])\n",
    "        for i in range(len(X_test[:,1])):\n",
    "            scal_prozv = np.dot(W,X_test[i])\n",
    "            if  round(1/(1+np.exp(-scal_prozv))) > 0.5:\n",
    "                Y_calculation = np.append(Y_calculation, 1)\n",
    "            else:\n",
    "                Y_calculation = np.append(Y_calculation, -1)\n",
    "                \n",
    "        score = 0\n",
    "        for i in range(len(X_test[:,1])):\n",
    "            if int(Y_calculation[i]) == int(Y_test[i]):\n",
    "                score = score + 1\n",
    "        return score/ len(X_test[:,1])\n",
    "\n",
    "\n",
    "# разделим на обучающую и тестовую выборку\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris_new_data, iris_new_target, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "model_logic = logistic_regression()\n",
    "# используем градиентный спуск для нахождения коэффициентов\n",
    "model_logic.gradient_descent(X_train,Y_train,0.01,5000)\n",
    "# используем метод Нестерова для нахождения коэффициентов\n",
    "model_logic.nesterov_gradient_descent(X_train,Y_train,0.01,5000)\n",
    "\n",
    "print(\"W = \",model_logic.W)\n",
    "print(\"Wnest = \",model_logic.W_nest)\n",
    "\n",
    "print(\"Score =\",model_logic.test(X_test, Y_test, model_logic.W))\n",
    "print(\"Score_nest =\",model_logic.test(X_test, Y_test, model_logic.W_nest))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62c42c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
